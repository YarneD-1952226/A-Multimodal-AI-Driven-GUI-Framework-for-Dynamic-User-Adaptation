### Design Log â€” Input Layer and Frontend (July 2025)

ðŸŽ® Input Modalities:
1. Webcam-based Gestures (MediaPipe Hands): open, point, fist, swipe.
2. Cursor (mouse): fallback and precise interaction.
3. Voice (optional): simple commands for accessibility.

ðŸ§© UI Components:
- Scroll view for items.
- Buttons (Play, Info, Confirm).
- Text elements.

âœ… Dynamic Behaviors:
- Size adaptation (scale when near).
- Position adaptation (move closer to user).
- Sticky effect (Apple TVâ€“style magnetic hover).
- Smooth animated transitions.

Architecture:
- Adapter Pattern to unify input modalities.
- Connects to backend AI adaptation logic.
- Frontend = Flutter 2D prototype (extendable to VR/Unity).

#### Generalized Adaptation Backend Design

Objective:
To create a modular, extensible adaptation backend that can dynamically adjust any UI using abstract context and user profile information.

Key Characteristics:
- Input-agnostic: Supports multiple input modalities (gestures, pointer, voice, future bio-signals).
- Output-agnostic: Provides high-level, abstract adaptation actions applicable across UI frameworks.
- Modularity: New features and accessibility options can be added without rewriting frontend logic.
- Platform-independence: Supports multiple frontends (Flutter, Unity, Web, VR).
- Future-proof: Designed to integrate LLM-based reasoning and on-device real-time adjustments.

Example future extensions:
- High-contrast mode
- Simplified layouts
- Dynamic text-to-speech
- Color adaptation for vision deficiencies

Next steps:
- Build simple Flutter app with scroll and button.
- Implement InputAdapter class to simulate modalities.
- Set up Python FastAPI service for adaptation logic.


### Design Log â€” Implementation Start (July 2025)

Frontend (Flutter):
- Scroll view with items/cards.
- Adaptive "Play" button with scale and offset animations.
- Input Adapter stub: currently simulating gestures with test buttons.

Backend (Python FastAPI):
- /adapt endpoint.
- Receives UI context (e.g., shaky_hand, hover_without_click).
- Returns JSON adaptation actions (e.g., scale factor, move closer).

Next steps:
- Connect Flutter to Python service (replace simulate buttons).
- Add real MediaPipe webcam input.
- Prepare periodic or real-time update mechanism.

#### Design Log â€” Backend Generalization (July 2025)

Objective:
Extend backend to support a generalized, modality-agnostic architecture for adaptive UI.

Endpoints:
- /adapt: Returns adaptation actions based on current context and user profile.
- /profile: Stores or updates user accessibility preferences (e.g., large buttons, color vision).
- /modalities: Lists and updates active input modalities (gestures, voice, cursor).

-> created venv and installed fastapi\[standard]
-> run via fastapi dev app.py

Features:
- Modular, easily extensible to new accessibility options.
- Backend logic decoupled from UI framework.
- Automatic logging of all decisions to JSONL file for reproducibility and thesis reporting.

Next steps:
- Connect frontend Flutter app to /adapt endpoint.
- Send actual or simulated context states.
- Visualize backend adaptation responses on UI.