@article{Oviatt1999,
  author     = {Oviatt, Sharon},
  title      = {Ten myths of multimodal interaction},
  year       = {1999},
  issue_date = {Nov. 1999},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {42},
  number     = {11},
  issn       = {0001-0782},
  url        = {https://doi.org/10.1145/319382.319398},
  doi        = {10.1145/319382.319398},
  journal    = {Commun. ACM},
  month      = nov,
  pages      = {74–81},
  numpages   = {8}
}

@inproceedings{kumar2007guide,
author = {Kumar, Manu and Winograd, Terry},
title = {GUIDe: gaze-enhanced UI design},
year = {2007},
isbn = {9781595936424},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240866.1240935},
doi = {10.1145/1240866.1240935},
abstract = {The GUIDe (Gaze-enhanced User Interface Design) project in the HCI Group at Stanford University explores how gaze information can be effectively used as an augmented input in addition to keyboard and mouse. We present three practical applications of gaze as an augmented input for pointing and selection, application switching, and scrolling. Our gaze-based interaction techniques do not overload the visual channel and present a natural, universally-accessible and general purpose use of gaze information to facilitate interaction with everyday computing devices.},
booktitle = {CHI '07 Extended Abstracts on Human Factors in Computing Systems},
pages = {1977–1982},
numpages = {6},
keywords = {application switching, automatic scrolling, eye pointing, eye tracking, pointing and selection, scrolling},
location = {San Jose, CA, USA},
series = {CHI EA '07}
}

@inproceedings{kumar2007guide2,
booktitle = {GUIDe: Gaze-enhanced UI Design, CHI: Conference on Human Factors in Computing Systems},
author = {Kumar, Manu and Winograd, Terry},
year = {2007},
month = {04},
pages = {1977-1982},
title = {GUIDe: gaze-enhanced UI design},
doi = {10.1145/1240866.1240935}
}

@InProceedings{luyten2001personalizing,
author="Luyten, Kris
and Coninx, Karin",
editor="Johnson, Chris",
title="An XML-Based Runtime User Interface Description Language for Mobile Computing Devices",
booktitle="Interactive Systems: Design, Specification, and Verification",
year="2001",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="1--15",
abstract="In a time where mobile computing devices and embedded systems gain importance, too much time is spent to reinventing user interfaces for each new device. To enhance future extensibility and reusability of systems and their user interfaces we propose a runtime user interface description language, which can cope with constraints found in embedded systems and mobile computing devices. XML seems to be a suitable tool to do this, when combined with Java. Following the evolution of Java towards XML, it is logical to introduce the concept applied to mobile computing devices and embedded systems.",
doi={10.1007/3-540-44664-0_1},
url={https://doi.org/10.1007/3-540-44664-0_1},
}

@inproceedings{Gajos2008SUPPLE,
author = {Gajos, Krzysztof and Weld, Daniel S.},
title = {SUPPLE: automatically generating user interfaces},
year = {2004},
isbn = {1581138156},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/964442.964461},
doi = {10.1145/964442.964461},
abstract = {In order to give people ubiquitous access to software applications, device controllers, and Internet services, it will be necessary to automatically adapt user interfaces to the computational devices at hand (eg, cell phones, PDAs, touch panels, etc.). While previous researchers have proposed solutions to this problem, each has limitations. This paper proposes a novel solution based on treating interface adaptation as an optimization problem. When asked to render an interface on a specific device, our supple system searches for the rendition that meets the device's constraints and minimizes the estimated effort for the user's expected interface actions. We make several contributions: 1) precisely defining the interface rendition problem, 2) demonstrating how user traces can be used to customize interface rendering to particular user's usage pattern, 3) presenting an efficient interface rendering algorithm, 4) performing experiments that demonstrate the utility of our approach.},
booktitle = {Proceedings of the 9th International Conference on Intelligent User Interfaces},
pages = {93–100},
numpages = {8},
keywords = {adaptive user interfaces, constraint satisfaction, decision theory, optimization, user interface generation, user trace},
location = {Funchal, Madeira, Portugal},
series = {IUI '04}
}


@book{Jerald2015VRBook,
author = {Jerald, Jason},
title = {The VR Book: Human-Centered Design for Virtual Reality},
year = {2015},
isbn = {9781970001129},
publisher = {Association for Computing Machinery and Morgan \& Claypool},
abstract = {Virtual reality (VR) can provide our minds with direct access to digital media in a way that seemingly has no limits. However, creating compelling VR experiences is an incredibly complex challenge. When VR is done well, the results are brilliant and pleasurable experiences that go beyond what we can do in the real world. When VR is done badly, not only is the system frustrating to use, but it can result in sickness. There are many causes of bad VR; some failures come from the limitations of technology, but many come from a lack of understanding perception, interaction, design principles, and real users. This book discusses these issues by emphasizing the human element of VR. The fact is, if we do not get the human element correct, then no amount of technology will make VR anything more than an interesting tool confined to research laboratories. Even when VR principles are fully understood, the first implementation is rarely novel and almost never ideal due to the complex nature of VR and the countless possibilities that can be created. The VR principles discussed in this book will enable readers to intelligently experiment with the rules and iteratively design towards innovative experiences.}
}

@inproceedings{7893331,
  author    = {Ortega, Francisco R. and Galvan, Alain and Tarre, Katherine and Barreto, Armando and Rishe, Naphtali and Bernal, Jonathan and Balcazar, Ruben and Thomas, Jason-Lee},
  booktitle = {2017 IEEE Symposium on 3D User Interfaces (3DUI)},
  title     = {Gesture elicitation for 3D travel via multi-touch and mid-Air systems for procedurally generated pseudo-universe},
  year      = {2017},
  volume    = {},
  number    = {},
  pages     = {144-153},
  keywords  = {Three-dimensional displays;Navigation;User interfaces;Visualization;Augmented reality;Engines;Resists;H.5.2 [User Interfaces]: User-centered design—Gesture Evaluation},
  doi       = {10.1109/3DUI.2017.7893331}
}
@inbook{Choudhury2015,
  author = {Choudhury, Ananya and Talukdar, Anjan and Sarma, Kandarpa},
  year   = {2015},
  month  = {08},
  pages  = {261-286},
  title  = {A Review on Vision-Based Hand Gesture Recognition and Applications},
  doi    = {10.4018/978-1-4666-8493-5.ch011}
}

@inproceedings{Cockburn2008Sticky,
  author    = {Cockburn, Andy and Gutwin, Carl and Alexander, Jason},
  title     = {Improving Pointing Performance by Mixing Control and Display Space: Control-Display Gain and Magnetic Pointer Fences},
  booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
  year      = {2008},
  pages     = {129--138},
  publisher = {ACM},
  address   = {Florence, Italy},
  doi       = {10.1145/1357054.1357074},
}

@book{Duchowski2017,
  author    = {Duchowski, Andrew T.},
  title     = {Eye Tracking Methodology: Theory and Practice},
  year      = {2017},
  edition   = {3},
  publisher = {Springer Cham},
  address   = {Cham},
  isbn      = {978-3-319-57881-1},
  doi       = {10.1007/978-3-319-57883-5},
  url       = {https://link.springer.com/book/10.1007/978-3-319-57883-5},
  note      = {eBook ISBN: 978-3-319-57883-5, Published: 24 May 2017, Softcover ISBN: 978-3-319-57881-1, Published: 07 June 2017, Number of Pages: XL, 366, Number of Illustrations: 71 b/w illustrations, 62 illustrations in colour}
}
@article{Fitts1954,
  title   = {The information capacity of the human motor system in controlling the amplitude of movement},
  author  = {Fitts, Paul M.},
  journal = {Journal of Experimental Psychology},
  volume  = {47},
  number  = {6},
  pages   = {381},
  year    = {1954},
  doi     = {10.1037//0096-3445.121.3.262}
}
@inproceedings{Gazeinteractioninthepost-WIMPworld,
  author = {Bulling, Andreas and Dachselt, Raimund and Duchowski, Andrew and Jacob, Robert and Stellmach, Sophie and Sundstedt, Veronica},
  year   = {2012},
  month  = {05},
  pages  = {1221-1224},
  title  = {Gaze interaction in the post-WIMP world},
  isbn   = {9781450310161},
  doi    = {10.1145/2212360.2212428}
}
@article{HCI-076,
  url     = {http://dx.doi.org/10.1561/1100000076},
  year    = {2018},
  volume  = {12},
  journal = {Foundations and Trends® in Human–Computer Interaction},
  title   = {10 Lenses to Design Sports-HCI},
  doi     = {10.1561/1100000076},
  issn    = {1551-3955},
  number  = {3},
  pages   = {172-237},
  author  = {Florian Mueller and Damon Young}
}
@article{Hoy02012018,
  author    = {Matthew B. Hoy},
  title     = {Alexa, Siri, Cortana, and More: An Introduction to Voice Assistants},
  journal   = {Medical Reference Services Quarterly},
  volume    = {37},
  number    = {1},
  pages     = {81--88},
  year      = {2018},
  publisher = {Routledge},
  doi       = {10.1080/02763869.2018.1404391},
  note      = {PMID: 29327988},
  url       = { 
               https://doi.org/10.1080/02763869.2018.1404391
               },
  eprint    = { 
               https://doi.org/10.1080/02763869.2018.1404391
               }
}

@misc{lugaresi2019mediapipeframeworkbuildingperception,
  title         = {MediaPipe: A Framework for Building Perception Pipelines},
  author        = {Camillo Lugaresi and Jiuqiang Tang and Hadon Nash and Chris McClanahan and Esha Uboweja and Michael Hays and Fan Zhang and Chuo-Ling Chang and Ming Guang Yong and Juhyun Lee and Wan-Teh Chang and Wei Hua and Manfred Georg and Matthias Grundmann},
  year          = {2019},
  eprint        = {1906.08172},
  archiveprefix = {arXiv},
  primaryclass  = {cs.DC},
  url           = {https://arxiv.org/abs/1906.08172}
}

@article{luyten2005profile,
  author = {Luyten, Kris and Thys, Kristof and Coninx, Karin},
  title  = {Profile-Aware Multi-Device Interfaces: An MPEG-21-Based Approach for Accessible User Interfaces},
  year   = {2005},
  doi    = {10.14236/ewic/AD2005.5}
}

@article{Marcotte2010Responsive,
  title={Responsive Web Design},
  author={Marcotte, Ethan},
  journal={A List Apart},
  number={306},
  year={2010},
  url={https://alistapart.com/article/responsive-web-design}
}

@inproceedings{Oviatt2004,
  author    = {Oviatt, Sharon and Coulston, Rachel and Lunsford, Rebecca},
  title     = {When do we interact multimodally? cognitive load and multimodal communication patterns},
  year      = {2004},
  isbn      = {1581139950},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/1027933.1027957},
  doi       = {10.1145/1027933.1027957},
  booktitle = {Proceedings of the 6th International Conference on Multimodal Interfaces},
  pages     = {129–136},
  numpages  = {8},
  keywords  = {cognitive load, dialogue context, human performance, individual differences, multimodal integration, multimodal interaction, speech and pen input, system adaptation, task difficulty, unimodal interaction},
  location  = {State College, PA, USA},
  series    = {ICMI '04}
}

@article{s21237825,
  author         = {Mizeraczyk, Jerzy and Studanski, Ryszard and Zak, Andrzej and Czapiewska, Agnieszka},
  title          = {A Method for Underwater Wireless Data Transmission in a Hydroacoustic Channel under NLOS Conditions},
  journal        = {Sensors},
  volume         = {21},
  year           = {2021},
  number         = {23},
  article-number = {7825},
  url            = {https://www.mdpi.com/1424-8220/21/23/7825},
  pubmedid       = {34883827},
  issn           = {1424-8220},
  doi            = {10.3390/s21237825}
}

@book{Wigdor2011BraveNUI,
author = {Wigdor, Daniel and Wixon, Dennis},
title = {Brave NUI World: Designing Natural User Interfaces for Touch and Gesture},
year = {2011},
isbn = {0123822319},
publisher = {Morgan Kaufmann Publishers Inc.},
address = {San Francisco, CA, USA},
edition = {1st},
abstract = {Touch and gesturaldeviceshave been hailed as next evolutionary step in human-computer interaction. As software companies struggle to catch up with one another in terms of developing the next great touch-based interface, designers are charged with the daunting task of keeping up with the advances innew technology and this new aspect to user experience design. Product and interaction designers, developers and managers are already well versed in UI design, but touch-based interfaces have added a new level of complexity. They need quick references and real-world examples in order to make informed decisions when designing for these particular interfaces. Brave NUI World is the first practical book for product and interaction developers and designing touch and gesture interfaces. Written by developers of industry-first, multi-touch, multi-user products, this book gives you the necessary tools and information to integrate touch and gesture practices into your daily work, presenting scenarios, problem solving, metaphors, and techniques intended to avoid making mistakes. *Provides easy-to-apply design guidance for the unique challenge of creating touch- and gesture-based user interfaces *Considers diverse user needs and context, real world successes and failures, and a look into the future of NUI *Presents thirty scenarios, giving practitioners a multitude of considerations for making informed design decisions and helping to ensure that missteps are never made again}
}

@article{Wu2024,
  author = {Jason Wu},
  title  = {{Computational Understanding of User Interfaces}},
  year   = {2024},
  month  = {8},
  url    = {https://kilthub.cmu.edu/articles/thesis/Computational_Understanding_of_User_Interfaces/26485132},
  doi    = {10.1184/R1/26485132.v1}
}

@article{Dey2001Context,
  title={Understanding and using context},
  author={Dey, Anind K.},
  journal={Personal and Ubiquitous Computing},
  volume={5},
  number={1},
  pages={4--7},
  year={2001},
url={https://doi.org/10.1007/s007790170019},
doi={10.1007/s007790170019}
}

@article{Schilit1994ContextAware,
  title={Context-aware computing applications},
  author={Schilit, Bill N. and Theimer, Marvin M.},
  journal={IEEE Workshop on Mobile Computing Systems and Applications},
  pages={85--90},
  year={1994},
doi={10.1109/WMCSA.1994.16},
}

@misc{gaspar2023learning,
      title={Learning from Interaction: User Interface Adaptation using Reinforcement Learning}, 
      author={Daniel Gaspar-Figueiredo},
      year={2023},
      eprint={2312.07216},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2312.07216}, 
}

@misc{baltrušaitis2017multimodalmachinelearningsurvey,
      title={Multimodal Machine Learning: A Survey and Taxonomy}, 
      author={Tadas Baltrušaitis and Chaitanya Ahuja and Louis-Philippe Morency},
      year={2017},
      eprint={1705.09406},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1705.09406}, 
}

@article{AtreyMultimodal,
author = {Atrey, Pradeep and Hossain, M. and El Saddik, Abdulmotaleb and Kankanhalli, Mohan},
year = {2010},
month = {11},
pages = {345-379},
title = {Multimodal fusion for multimedia analysis: A survey},
volume = {16},
journal = {Multimedia Syst.},
doi = {10.1007/s00530-010-0182-0}
}

@inproceedings{mobileui,
author = {Wang, Bryan and Li, Gang and Li, Yang},
title = {Enabling Conversational Interaction with Mobile UI using Large Language Models},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580895},
doi = {10.1145/3544548.3580895},
abstract = {Conversational agents show the promise to allow users to interact with mobile devices using language. However, to perform diverse UI tasks with natural language, developers typically need to create separate datasets and models for each specific task, which is expensive and effort-consuming. Recently, pre-trained large language models (LLMs) have been shown capable of generalizing to various downstream tasks when prompted with a handful of examples from the target task. This paper investigates the feasibility of enabling versatile conversational interactions with mobile UIs using a single LLM. We designed prompting techniques to adapt an LLM to mobile UIs. We experimented with four important modeling tasks that address various scenarios in conversational interaction. Our method achieved competitive performance on these challenging tasks without requiring dedicated datasets and training, offering a lightweight and generalizable approach to enable language-based mobile interaction.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {432},
numpages = {17},
keywords = {Conversational Interaction, Large Language Models, Mobile UI},
location = {Hamburg, Germany},
series = {CHI '23}
}

@misc{yao2023react,
      title={ReAct: Synergizing Reasoning and Acting in Language Models}, 
      author={Shunyu Yao and Jeffrey Zhao and Dian Yu and Nan Du and Izhak Shafran and Karthik Narasimhan and Yuan Cao},
      year={2023},
      eprint={2210.03629},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2210.03629}, 
}

@misc{zheng2024gpt4visiongeneralistwebagent,
      title={GPT-4V(ision) is a Generalist Web Agent, if Grounded}, 
      author={Boyuan Zheng and Boyu Gou and Jihyung Kil and Huan Sun and Yu Su},
      year={2024},
      eprint={2401.01614},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2401.01614}, 
}

@misc{surís2023vipergptvisualinferencepython,
      title={ViperGPT: Visual Inference via Python Execution for Reasoning}, 
      author={Dídac Surís and Sachit Menon and Carl Vondrick},
      year={2023},
      eprint={2303.08128},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2303.08128}, 
}

@article{fitzpatrick2017delivering,
author="Fitzpatrick, Kathleen Kara
and Darcy, Alison
and Vierhile, Molly",
title="Delivering Cognitive Behavior Therapy to Young Adults With Symptoms of Depression and Anxiety Using a Fully Automated Conversational Agent (Woebot): A Randomized Controlled Trial",
journal="JMIR Ment Health",
year="2017",
month="6",
day="06",
volume="4",
number="2",
pages="e19",
keywords="conversational agents; mobile mental health; mental health; chatbots; depression; anxiety; college students; digital health",
abstract="Background: Web-based cognitive-behavioral therapeutic (CBT) apps have demonstrated efficacy but are characterized by poor adherence. Conversational agents may offer a convenient, engaging way of getting support at any time. Objective: The objective of the study was to determine the feasibility, acceptability, and preliminary efficacy of a fully automated conversational agent to deliver a self-help program for college students who self-identify as having symptoms of anxiety and depression. Methods: In an unblinded trial, 70 individuals age 18-28 years were recruited online from a university community social media site and were randomized to receive either 2 weeks (up to 20 sessions) of self-help content derived from CBT principles in a conversational format with a text-based conversational agent (Woebot) (n=34) or were directed to the National Institute of Mental Health ebook, ``Depression in College Students,'' as an information-only control group (n=36). All participants completed Web-based versions of the 9-item Patient Health Questionnaire (PHQ-9), the 7-item Generalized Anxiety Disorder scale (GAD-7), and the Positive and Negative Affect Scale at baseline and 2-3 weeks later (T2). Results: Participants were on average 22.2 years old (SD 2.33), 67{\%} female (47/70), mostly non-Hispanic (93{\%}, 54/58), and Caucasian (79{\%}, 46/58). Participants in the Woebot group engaged with the conversational agent an average of 12.14 (SD 2.23) times over the study period. No significant differences existed between the groups at baseline, and 83{\%} (58/70) of participants provided data at T2 (17{\%} attrition). Intent-to-treat univariate analysis of covariance revealed a significant group difference on depression such that those in the Woebot group significantly reduced their symptoms of depression over the study period as measured by the PHQ-9 (F=6.47; P=.01) while those in the information control group did not. In an analysis of completers, participants in both groups significantly reduced anxiety as measured by the GAD-7 (F1,54= 9.24; P=.004). Participants' comments suggest that process factors were more influential on their acceptability of the program than content factors mirroring traditional therapy. Conclusions: Conversational agents appear to be a feasible, engaging, and effective way to deliver CBT. ",
issn="2368-7959",
doi="10.2196/mental.7785",
url="http://mental.jmir.org/2017/2/e19/",
url="https://doi.org/10.2196/mental.7785",
url="http://www.ncbi.nlm.nih.gov/pubmed/28588005"
}

@article{Toelle2019,
  author = {Toelle, T. R. and Utpadel-Fischler, D. A. and Haas, K. K. and Priebe, J. A.},
  title = {App-based multidisciplinary back pain treatment versus combined physiotherapy plus online education: a randomized controlled trial},
  journal = {NPJ Digital Medicine},
  year = {2019},
  volume = {2},
  number = {1},
  pages = {34},
  month = {5},
  doi = {10.1038/s41746-019-0109-x},
  pmid = {31304380},
  pmcid = {PMC6550294}
}

@inproceedings{Dixon,
author = {Dixon, Morgan and Fogarty, James and Wobbrock, Jacob},
title = {A general-purpose target-aware pointing enhancement using pixel-level analysis of graphical interfaces},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208734},
doi = {10.1145/2207676.2208734},
abstract = {We present a general-purpose implementation of a target aware pointing technique, functional across an entire desktop and independent of application implementations. Specifically, we implement Grossman and Balakrishnan's Bubble Cursor, the fastest general pointing facilitation technique in the literature. Our implementation obtains the necessary knowledge of interface targets using a combination of pixel-level analysis and social annotation. We discuss the most novel aspects of our implementation, including methods for interactive creation and correction of pixel-level prototypes of interface elements and methods for interactive annotation of how the cursor should select identified elements. We also report on limitations of the Bubble Cursor unearthed by examining our implementation in the complexity of real-world interfaces. We therefore contribute important progress toward real-world deployment of an important family of techniques and shed light on the gap between understanding techniques in controlled settings versus behavior with real-world interfaces.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3167–3176},
numpages = {10},
keywords = {bubble cursor, pixel-based reverse engineering, prefab, real-world interfaces, social annotation, target-aware pointing},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@article{10.1145/965105.807503,
author = {Bolt, Richard A.},
title = {“Put-that-there”: Voice and gesture at the graphics interface},
year = {1980},
issue_date = {July 1980},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {3},
issn = {0097-8930},
url = {https://doi.org/10.1145/965105.807503},
doi = {10.1145/965105.807503},
abstract = {Recent technological advances in connected-speech recognition and position sensing in space have encouraged the notion that voice and gesture inputs at the graphics interface can converge to provide a concerted, natural user modality.The work described herein involves the user commanding simple shapes about a large-screen graphics display surface. Because voice can be augmented with simultaneous pointing, the free usage of pronouns becomes possible, with a corresponding gain in naturalness and economy of expression. Conversely, gesture aided by voice gains precision in its power to reference.},
journal = {SIGGRAPH Comput. Graph.},
month = jul,
pages = {262–270},
numpages = {9},
keywords = {Gesture, Graphics, Graphics interface, Man-machine interfaces, Space sensing, Spatial data management, Speech input, Voice input}
}

@inproceedings{Bolt1980,
author = {Bolt, Richard A.},
title = {“Put-that-there”: Voice and gesture at the graphics interface},
year = {1980},
isbn = {0897910214},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800250.807503},
doi = {10.1145/800250.807503},
abstract = {Recent technological advances in connected-speech recognition and position sensing in space have encouraged the notion that voice and gesture inputs at the graphics interface can converge to provide a concerted, natural user modality.The work described herein involves the user commanding simple shapes about a large-screen graphics display surface. Because voice can be augmented with simultaneous pointing, the free usage of pronouns becomes possible, with a corresponding gain in naturalness and economy of expression. Conversely, gesture aided by voice gains precision in its power to reference.},
booktitle = {Proceedings of the 7th Annual Conference on Computer Graphics and Interactive Techniques},
pages = {262–270},
numpages = {9},
keywords = {Gesture, Graphics, Graphics interface, Man-machine interfaces, Space sensing, Spatial data management, Speech input, Voice input},
location = {Seattle, Washington, USA},
series = {SIGGRAPH '80}
}

@article{Gajos2010Supple,
  author  = {Krzysztof Z. Gajos and Daniel S. Weld and Jacob O. Wobbrock},
  title   = {Automatically Generating Personalized User Interfaces with SUPPLE},
  journal = {Artificial Intelligence},
  volume  = {174},
  number  = {12--13},
  pages   = {910--950},
  year    = {2010},
  doi     = {10.1016/j.artint.2010.05.005}
}

@article{Wobbrock2011ABD,
  author  = {Jacob O. Wobbrock and Shaun K. Kane and Krzysztof Z. Gajos and Susumu Harada and Jon Froehlich},
  title   = {Ability-Based Design: Concept, Principles, and Examples},
  journal = {ACM Transactions on Accessible Computing},
  volume  = {3},
  number  = {3},
  articleno = {9},
  year    = {2011},
  doi     = {10.1145/1952383.1952384}
}

@inproceedings{Findlater2004Menus,
  author    = {Leah Findlater and Joanna McGrenere},
  title     = {A Comparison of Static, Adaptive, and Adaptable Menus},
  booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '04)},
  pages     = {89--96},
  year      = {2004},
  publisher = {ACM},
  doi       = {10.1145/985692.985704}
}

@inproceedings{Findlater2009Ephemeral,
  author    = {Leah Findlater and Karyn Moffatt and Joanna McGrenere and Jessica Dawson},
  title     = {Ephemeral Adaptation: The Use of Gradual Onset to Improve Menu Selection Performance},
  booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '09)},
  pages     = {1655--1664},
  year      = {2009},
  publisher = {ACM},
  doi       = {10.1145/1518701.1518956}
}

@article{Sears1994SplitMenus,
  author  = {Andrew Sears and Ben Shneiderman},
  title   = {Split Menus: Effectively Using Selection Frequency to Organize Menus},
  journal = {ACM Transactions on Computer-Human Interaction},
  volume  = {1},
  number  = {1},
  pages   = {27--51},
  year    = {1994},
  doi     = {10.1145/174630.174632}
}

@incollection{Jameson2003Adaptive,
  author    = {Anthony Jameson},
  title     = {Adaptive Interfaces and Agents},
  booktitle = {The Human-Computer Interaction Handbook: Fundamentals, Evolving Technologies and Emerging Applications},
  editor    = {Julie A. Jacko and Andrew Sears},
  pages     = {305--330},
  year      = {2003},
  publisher = {Lawrence Erlbaum Associates},
    isbn = {0805838384}
}

@inproceedings{Wobbrock2009AngleMouse,
  author    = {Jacob O. Wobbrock and James Fogarty and Shih-Yen Liu and Shunichi Kimuro and Susumu Harada},
  title     = {The Angle Mouse: Target-Agnostic Dynamic Gain Adjustment Based on Angular Deviation},
  booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '09)},
  pages     = {1401--1410},
  year      = {2009},
  publisher = {ACM},
  doi       = {10.1145/1518701.1518912}
}

@article{Sarsenbayeva2022Motor,
  author  = {Zhanna Sarsenbayeva and Niels van Berkel and Eduardo Velloso and Jorge Gon{\c{c}}alves and Vassilis Kostakos},
  title   = {Methodological Standards in Accessibility Research on Motor Impairments: A Survey},
  journal = {ACM Computing Surveys},
  volume  = {55},
  number  = {7},
  articleno = {143},
  pages   = {1--35},
  year    = {2022},
  doi     = {10.1145/3543509}
}

@article{Myers2000Tools,
  author    = {Brad A. Myers and Scott E. Hudson and Randy Pausch},
  title     = {Past, present, and future of user interface software tools},
  journal   = {ACM Transactions on Computer-Human Interaction},
  volume    = {7},
  number    = {1},
  pages     = {3--28},
  year      = {2000},
  doi       = {10.1145/344949.344959}
}

@article{Calvary2003Cameleon,
  author    = {Ga{\"e}lle Calvary and Jo{\"e}lle Coutaz and David Thevenin and Quentin Limbourg and Laurent Bouillon and Jean Vanderdonckt},
  title     = {A Unifying Reference Framework for Multi-Target User Interfaces},
  journal   = {Interacting with Computers},
  volume    = {15},
  number    = {3},
  pages     = {289--308},
  year      = {2003},
  doi       = {10.1016/S0953-5438(03)00010-9}
}

@online{Marcotte2010RWD,
  author    = {Ethan Marcotte},
  title     = {Responsive Web Design},
  year      = {2010},
  url       = {https://alistapart.com/article/responsive-web-design/},
  note      = {A List Apart, Issue 306}
}

@techreport{W3C2012MediaQueries,
  author      = {H{\aa}kon Wium Lie and Tantek {\c{C}}elik and Daniel Glazman and Anne van Kesteren and Florian Rivoal},
  title       = {Media Queries Level 3},
  institution = {World Wide Web Consortium (W3C)},
  year        = {2012},
  url         = {https://www.w3.org/TR/mediaqueries-3/},
  note        = {W3C Recommendation}
}

@article{Badros2001Cassowary,
  author    = {Greg J. Badros and Alan Borning and Peter J. Stuckey},
  title     = {The Cassowary Linear Arithmetic Constraint Solving Algorithm},
  journal   = {ACM Transactions on Computer-Human Interaction},
  volume    = {8},
  number    = {4},
  pages     = {267--306},
  year      = {2001},
  doi       = {10.1145/504704.504705}
}

@article{Baldauf2007ContextSurvey,
  author    = {Matthias Baldauf and Schahram Dustdar and Florian Rosenberg},
  title     = {A survey on context-aware systems},
  journal   = {International Journal of Ad Hoc and Ubiquitous Computing},
  volume    = {2},
  number    = {4},
  pages     = {263--277},
  year      = {2007},
  doi       = {10.1504/IJAHUC.2007.014070}
}

@inproceedings{Akiki2014EnterpriseAdaptive,
  author    = {Pierre A. Akiki and Arosha K. Bandara and Yijun Yu},
  title     = {Integrating adaptive user interface capabilities in enterprise applications},
  booktitle = {Companion Proceedings of the 36th International Conference on Software Engineering (ICSE)},
  year      = {2014},
  pages     = {487--490},
  publisher = {ACM},
  doi       = {10.1145/2568225.2568230}
}

@inproceedings{Lin2003RoleBased,
  author    = {Yi-Jung Lin and Stuart Speedie},
  title     = {Role-Based and Adaptive User Interface Designs in a Teledermatology Consult System: A Way to Secure and a Way to Enhance},
  booktitle = {AMIA Annual Symposium Proceedings},
  year      = {2003},
  pages     = {913},
  publisher = {American Medical Informatics Association},
  url       = {https://pmc.ncbi.nlm.nih.gov/articles/PMC1480225/}
}
